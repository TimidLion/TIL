## torch.nn.functional.log_softmax function

**It is different function with [torch.nn.LogSoftmax function](torch_LogSoftmax.md)**

**While both are same as mathematically.**

This function uses alternative formulation to compute the output and gradient correctly. 

IT MEANS IT IS FASTER ANS STABLER.
